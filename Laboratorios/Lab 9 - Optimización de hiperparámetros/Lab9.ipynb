{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "b5c0d2440b3e4995a794ded565213150",
        "deepnote_cell_type": "markdown",
        "id": "_Mql1uRoI5v5"
      },
      "source": [
        "<h1><center>Laboratorio 9: Optimizaci칩n de modelos 游눮</center></h1>\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programaci칩n Cient칤fica para Ciencia de Datos - Primavera 2024</strong></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "bfb94b9656f145ad83e81b75d218cb70",
        "deepnote_cell_type": "markdown",
        "id": "FAPGIlEAI5v8"
      },
      "source": [
        "### **Cuerpo Docente:**\n",
        "\n",
        "- Profesores: Ignacio Meza, Sebasti치n Tinoco\n",
        "- Auxiliar: Eduardo Moya\n",
        "- Ayudantes: Nicol치s Ojeda, Melanie Pe침a, Valentina Rojas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "b1b537fdd27c43909a49d3476ce64d91",
        "deepnote_cell_type": "markdown",
        "id": "8NozgbkZI5v9"
      },
      "source": [
        "### Equipo: Ratas.py 游내\n",
        "\n",
        "- Nombre de alumno 1: Geraldyn P칠rez\n",
        "- Nombre de alumno 2: Diego Rojas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Link de repositorio de GitHub:** [Repositorio](https://github.com/Geral37/MDS7202.git)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "b7dbdd30ab544cb8a8afe00648a586ae",
        "deepnote_cell_type": "markdown",
        "id": "vHU9DI6wI5v9"
      },
      "source": [
        "### Temas a tratar\n",
        "\n",
        "- Predicci칩n de demanda usando `xgboost`\n",
        "- B칰squeda del modelo 칩ptimo de clasificaci칩n usando `optuna`\n",
        "- Uso de pipelines.\n",
        "\n",
        "### Reglas:\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser치n respondidos por este medio.\n",
        "- Prohibidas las copias.\n",
        "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
        "- C칩digo que no se pueda ejecutar, no ser치 revisado.\n",
        "\n",
        "### Objetivos principales del laboratorio\n",
        "\n",
        "- Optimizar modelos usando `optuna`\n",
        "- Recurrir a t칠cnicas de *prunning*\n",
        "- Forzar el aprendizaje de relaciones entre variables mediante *constraints*\n",
        "- Fijar un pipeline con un modelo base que luego se ir치 optimizando.\n",
        "\n",
        "El laboratorio deber치 ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al m치ximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante m치s eficientes que los iteradores nativos sobre DataFrames."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "f1c73babb7f74af588a4fa6ae14829e0",
        "deepnote_cell_type": "markdown",
        "id": "U_-sNOuOI5v9"
      },
      "source": [
        "# Importamos librerias 칰tiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cell_id": "51afe4d2df42442b9e5402ffece60ead",
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 4957,
        "execution_start": 1699544354044,
        "id": "ekHbM85NI5v9",
        "source_hash": null
      },
      "outputs": [],
      "source": [
        "!pip install -qq xgboost optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6hJXpLCSspz"
      },
      "source": [
        "# El emprendimiento de Fiu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "44d227389a734ac59189c5e0005bc68a",
        "deepnote_cell_type": "markdown",
        "id": "b0bDalAOI5v-"
      },
      "source": [
        "Tras liderar de manera exitosa la implementaci칩n de un proyecto de ciencia de datos para caracterizar los datos generados en Santiago 2023, el misterioso corp칩reo **Fiu** se anima y decide levantar su propio negocio de consultor칤a en machine learning. Tras varias e intensas negociaciones, Fiu logra encontrar su *primera chamba*: predecir la demanda (cantidad de venta) de una famosa productora de bebidas de calibre mundial. Al ver el gran potencial y talento que usted ha demostrado en el campo de la ciencia de datos, Fiu lo contrata como data scientist para que forme parte de su nuevo emprendimiento.\n",
        "\n",
        "Para este laboratorio deben trabajar con los datos `sales.csv` subidos a u-cursos, el cual contiene una muestra de ventas de la empresa para diferentes productos en un determinado tiempo.\n",
        "\n",
        "Para comenzar, cargue el dataset se침alado y visualice a trav칠s de un `.head` los atributos que posee el dataset.\n",
        "\n",
        "<i><p align=\"center\">Fiu siendo felicitado por su excelente desempe침o en el proyecto de caracterizaci칩n de datos</p></i>\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media-front.elmostrador.cl/2023/09/A_UNO_1506411_2440e.jpg\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cell_id": "2f9c82d204b14515ad27ae07e0b77702",
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 92,
        "execution_start": 1699544359006,
        "id": "QvMPOqHuI5v-",
        "outputId": "659e7a12-d74d-45d6-d3c2-33a6cd338585",
        "source_hash": null
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>city</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>pop</th>\n",
              "      <th>shop</th>\n",
              "      <th>brand</th>\n",
              "      <th>container</th>\n",
              "      <th>capacity</th>\n",
              "      <th>price</th>\n",
              "      <th>quantity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>31/01/12</td>\n",
              "      <td>Athens</td>\n",
              "      <td>37.97945</td>\n",
              "      <td>23.71622</td>\n",
              "      <td>672130</td>\n",
              "      <td>shop_1</td>\n",
              "      <td>kinder-cola</td>\n",
              "      <td>glass</td>\n",
              "      <td>500ml</td>\n",
              "      <td>0.96</td>\n",
              "      <td>13280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>31/01/12</td>\n",
              "      <td>Athens</td>\n",
              "      <td>37.97945</td>\n",
              "      <td>23.71622</td>\n",
              "      <td>672130</td>\n",
              "      <td>shop_1</td>\n",
              "      <td>kinder-cola</td>\n",
              "      <td>plastic</td>\n",
              "      <td>1.5lt</td>\n",
              "      <td>2.86</td>\n",
              "      <td>6727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>31/01/12</td>\n",
              "      <td>Athens</td>\n",
              "      <td>37.97945</td>\n",
              "      <td>23.71622</td>\n",
              "      <td>672130</td>\n",
              "      <td>shop_1</td>\n",
              "      <td>kinder-cola</td>\n",
              "      <td>can</td>\n",
              "      <td>330ml</td>\n",
              "      <td>0.87</td>\n",
              "      <td>9848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>31/01/12</td>\n",
              "      <td>Athens</td>\n",
              "      <td>37.97945</td>\n",
              "      <td>23.71622</td>\n",
              "      <td>672130</td>\n",
              "      <td>shop_1</td>\n",
              "      <td>adult-cola</td>\n",
              "      <td>glass</td>\n",
              "      <td>500ml</td>\n",
              "      <td>1.00</td>\n",
              "      <td>20050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>31/01/12</td>\n",
              "      <td>Athens</td>\n",
              "      <td>37.97945</td>\n",
              "      <td>23.71622</td>\n",
              "      <td>672130</td>\n",
              "      <td>shop_1</td>\n",
              "      <td>adult-cola</td>\n",
              "      <td>can</td>\n",
              "      <td>330ml</td>\n",
              "      <td>0.39</td>\n",
              "      <td>25696</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id      date    city       lat      long     pop    shop        brand  \\\n",
              "0   0  31/01/12  Athens  37.97945  23.71622  672130  shop_1  kinder-cola   \n",
              "1   1  31/01/12  Athens  37.97945  23.71622  672130  shop_1  kinder-cola   \n",
              "2   2  31/01/12  Athens  37.97945  23.71622  672130  shop_1  kinder-cola   \n",
              "3   3  31/01/12  Athens  37.97945  23.71622  672130  shop_1   adult-cola   \n",
              "4   4  31/01/12  Athens  37.97945  23.71622  672130  shop_1   adult-cola   \n",
              "\n",
              "  container capacity  price  quantity  \n",
              "0     glass    500ml   0.96     13280  \n",
              "1   plastic    1.5lt   2.86      6727  \n",
              "2       can    330ml   0.87      9848  \n",
              "3     glass    500ml   1.00     20050  \n",
              "4       can    330ml   0.39     25696  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "df = pd.read_csv('sales.csv')\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['id', 'date', 'city', 'lat', 'long', 'pop', 'shop', 'brand',\n",
              "       'container', 'capacity', 'price', 'quantity'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "b50db6f2cb804932ae3f9e5748a6ea61",
        "deepnote_cell_type": "markdown",
        "id": "pk4ru76pI5v_"
      },
      "source": [
        "## 1 Generando un Baseline (5 puntos)\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media.tenor.com/O-lan6TkadUAAAAC/what-i-wnna-do-after-a-baseline.gif\">\n",
        "</p>\n",
        "\n",
        "Antes de entrenar un algoritmo, usted recuerda los apuntes de su mag칤ster en ciencia de datos y recuerda que debe seguir una serie de *buenas pr치cticas* para entrenar correcta y debidamente su modelo. Despu칠s de un par de vueltas, llega a las siguientes tareas:\n",
        "\n",
        "1. Separe los datos en conjuntos de train (70%), validation (20%) y test (10%). Fije una semilla para controlar la aleatoriedad. [0.5 puntos]\n",
        "2. Implemente un `FunctionTransformer` para extraer el d칤a, mes y a침o de la variable `date`. Guarde estas variables en el formato categorical de pandas. [1 punto]\n",
        "3. Implemente un `ColumnTransformer` para procesar de manera adecuada los datos num칠ricos y categ칩ricos. Use `OneHotEncoder` para las variables categ칩ricas. `Nota:` Utilice el m칠todo `.set_output(transform='pandas')` para obtener un DataFrame como salida del `ColumnTransformer` [1 punto]\n",
        "4. Guarde los pasos anteriores en un `Pipeline`, dejando como 칰ltimo paso el regresor `DummyRegressor` para generar predicciones en base a promedios. [0.5 punto]\n",
        "5. Entrene el pipeline anterior y reporte la m칠trica `mean_absolute_error` sobre los datos de validaci칩n. 쮺칩mo se interpreta esta m칠trica para el contexto del negocio? [0.5 puntos]\n",
        "6. Finalmente, vuelva a entrenar el `Pipeline` pero esta vez usando `XGBRegressor` como modelo **utilizando los par치metros por default**. 쮺칩mo cambia el MAE al implementar este algoritmo? 쮼s mejor o peor que el `DummyRegressor`? [1 punto]\n",
        "7. Guarde ambos modelos en un archivo .pkl (uno cada uno) [0.5 puntos]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
        "from sklearn.dummy import DummyRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn import set_config\n",
        "set_config(transform_output=\"pandas\")\n",
        "from xgboost import XGBRegressor\n",
        "import joblib "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cell_id": "1482c992d9494e5582b23dbd3431dbfd",
        "deepnote_cell_type": "code",
        "id": "sfnN7HubI5v_"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\geral\\AppData\\Local\\Temp\\ipykernel_21656\\1374751225.py:9: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df['date'] = pd.to_datetime(df['date'])\n",
            "C:\\Users\\geral\\AppData\\Local\\Temp\\ipykernel_21656\\1374751225.py:9: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df['date'] = pd.to_datetime(df['date'])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error (MAE) en los datos de validaci칩n para DummyRegressor: 13590.765980053535\n",
            "Mean Absolute Error (MAE) en los datos de validaci칩n para XGBRegressor: 2512.876669849828\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['xgb_model.pkl']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Inserte su c칩digo ac치\n",
        "# 1. \n",
        "seed=1705\n",
        "train, resto = train_test_split(df, test_size=0.3,random_state=seed)\n",
        "val, test = train_test_split(resto, test_size=1/3, random_state=seed)\n",
        "\n",
        "# 2.\n",
        "def extract_date_features(df):\n",
        "    df['date'] = pd.to_datetime(df['date'])  \n",
        "    df['day'] = df['date'].dt.day.astype('category')\n",
        "    df['month'] = df['date'].dt.month.astype('category')\n",
        "    df['year'] = df['date'].dt.year.astype('category')\n",
        "    return df\n",
        "\n",
        "date_transformer = FunctionTransformer(extract_date_features)\n",
        "\n",
        "# 3.\n",
        "categorical_cols = ['city', 'shop', 'brand', 'container', 'capacity', 'day', 'month', 'year']\n",
        "numeric_cols = ['lat', 'long', 'pop', 'price']\n",
        "\n",
        "numeric_transformer = StandardScaler()\n",
        "categorical_transformer = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)\n",
        "    ]\n",
        ")\n",
        "\n",
        "preprocessor.set_output(transform='pandas')\n",
        "\n",
        "# 4.\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('date_extractor', date_transformer),   # Extraer d칤a, mes, a침o\n",
        "    ('preprocessor', preprocessor),         # Preprocesar num칠rico y categ칩rico\n",
        "    ('regressor', DummyRegressor(strategy=\"mean\"))  # Regresor Dummy\n",
        "])\n",
        "\n",
        "# 5.\n",
        "X_train = train.drop(columns='quantity')\n",
        "y_train = train['quantity']\n",
        "\n",
        "X_val = val.drop(columns='quantity')\n",
        "y_val = val['quantity']\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "y_pred = pipeline.predict(X_val)\n",
        "\n",
        "mae = mean_absolute_error(y_val, y_pred)\n",
        "print(f'Mean Absolute Error (MAE) en los datos de validaci칩n para DummyRegressor: {mae}')\n",
        "\n",
        "# 6.\n",
        "pipeline2 = Pipeline(steps=[\n",
        "    ('date_extractor', date_transformer),   # Extraer d칤a, mes, a침o\n",
        "    ('preprocessor', preprocessor),         # Preprocesar num칠rico y categ칩rico\n",
        "    ('regressor', XGBRegressor())  # XGBRegressor como modelo\n",
        "])\n",
        "\n",
        "pipeline2.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred2 = pipeline2.predict(X_val)\n",
        "\n",
        "\n",
        "mae = mean_absolute_error(y_val, y_pred2)\n",
        "print(f'Mean Absolute Error (MAE) en los datos de validaci칩n para XGBRegressor: {mae}')\n",
        "\n",
        "# 7.\n",
        "joblib.dump(pipeline, 'dummy_model.pkl')\n",
        "joblib.dump(pipeline2, 'xgb_model.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5. \n",
        "\n",
        "6. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "7e17e46063774ec28226fe300d42ffe0",
        "deepnote_cell_type": "markdown",
        "id": "wnyMINdKI5v_"
      },
      "source": [
        "## 2. Forzando relaciones entre par치metros con XGBoost (10 puntos)\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://64.media.tumblr.com/14cc45f9610a6ee341a45fd0d68f4dde/20d11b36022bca7b-bf/s640x960/67ab1db12ff73a530f649ac455c000945d99c0d6.gif\">\n",
        "</p>\n",
        "\n",
        "Un colega aficionado a la econom칤a le *sopla* que la demanda guarda una relaci칩n inversa con el precio del producto. Motivado para impresionar al querido corp칩reo, se propone hacer uso de esta informaci칩n para mejorar su modelo realizando las siguientes tareas:\n",
        "\n",
        "1. Vuelva a entrenar el `Pipeline` con `XGBRegressor`, pero esta vez forzando una relaci칩n mon칩tona negativa entre el precio y la cantidad. Para aplicar esta restricci칩n ap칩yese en la siguiente <a href = https://xgboost.readthedocs.io/en/stable/tutorials/monotonic.html>documentaci칩n</a>. [6 puntos]\n",
        "\n",
        ">Hint 1: Para implementar el constraint se le sugiere hacerlo especificando el nombre de la variable. De ser as칤, probablemente le sea 칰til **mantener el formato de pandas** antes del step de entrenamiento.\n",
        "\n",
        ">Hint 2: Puede obtener el nombre de las columnas en el paso anterior al modelo regresor mediante el m칠todo `.get_feature_names_out()`\n",
        "\n",
        "2. Luego, vuelva a reportar el `MAE` sobre el conjunto de validaci칩n. [1 puntos]\n",
        "\n",
        "3. 쮺칩mo cambia el error al incluir esta relaci칩n? 쯊en칤a raz칩n su amigo? [2 puntos]\n",
        "\n",
        "4. Guarde su modelo en un archivo .pkl [1 punto]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['id', 'date', 'city', 'lat', 'long', 'pop', 'shop', 'brand',\n",
              "       'container', 'capacity', 'price', 'quantity'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "cell_id": "f469f3b572be434191d2d5c3f11b20d2",
        "deepnote_cell_type": "code",
        "id": "B7tMnkiAI5v_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error (MAE) en los datos de validaci칩n para la relaci칩n forzada: 2442.134453162661\n"
          ]
        }
      ],
      "source": [
        "# Obtener los nombres de las caracter칤sticas procesadas\n",
        "feature_names = pipeline2.named_steps['preprocessor'].get_feature_names_out()\n",
        "\n",
        "# Crear la lista de restricciones para cada feature\n",
        "monotonic_constraints = [0] * len(feature_names)  # Lista con 0's para todas las caracter칤sticas\n",
        "\n",
        "# Aplicar restricci칩n -1 a la caracter칤stica 'num__price'\n",
        "if 'num__price' in feature_names:\n",
        "    monotonic_constraints[feature_names.tolist().index('num__price')] = -1  # Asignar -1 a 'num__price'\n",
        "\n",
        "# Convertir la lista a formato requerido por XGBoost (string con valores separados por comas)\n",
        "monotonic_constraints_str = '(' + ','.join(map(str, monotonic_constraints)) + ')'\n",
        "\n",
        "# Redefinir el pipeline con la restricci칩n aplicada en XGBRegressor\n",
        "pipeline21 = Pipeline(steps=[\n",
        "    ('date_extractor', date_transformer),\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', XGBRegressor(monotone_constraints=monotonic_constraints_str))\n",
        "])\n",
        "\n",
        "# Entrenar el pipeline de nuevo\n",
        "pipeline21.fit(X_train, y_train)\n",
        "\n",
        "# Predecir y evaluar\n",
        "y_pred = pipeline21.predict(X_val)\n",
        "mae = mean_absolute_error(y_val, y_pred)\n",
        "print(f'Mean Absolute Error (MAE) en los datos de validaci칩n para la relaci칩n forzada: {mae}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. El MAE se reduce de 2512 a 2442 unidades en promedio. Asi que el amigo s칤 ten칤a raz칩n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['xgb_model_con_rmn.pkl']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "joblib.dump(pipeline21, 'xgb_model_con_rmn.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "e59ef80ed20b4de8921f24da74e87374",
        "deepnote_cell_type": "markdown",
        "id": "5D5-tX4dI5v_"
      },
      "source": [
        "## 3. Optimizaci칩n de Hiperpar치metros con Optuna (20 puntos)\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media.tenor.com/fmNdyGN4z5kAAAAi/hacking-lucy.gif\">\n",
        "</p>\n",
        "\n",
        "Luego de presentarle sus resultados, Fiu le pregunta si es posible mejorar *aun m치s* su modelo. En particular, le comenta de la optimizaci칩n de hiperpar치metros con metodolog칤as bayesianas a trav칠s del paquete `optuna`. Como usted es un aficionado al entrenamiento de modelos de ML, se propone implementar la descabellada idea de su jefe.\n",
        "\n",
        "A partir de la mejor configuraci칩n obtenida en la secci칩n anterior, utilice `optuna` para optimizar sus hiperpar치metros. En particular, se pide que su optimizaci칩n considere lo siguiente:\n",
        "\n",
        "- Fijar una semilla en las instancias necesarias para garantizar la reproducibilidad de resultados\n",
        "- Utilice `TPESampler` como m칠todo de muestreo\n",
        "- De `XGBRegressor`, optimice los siguientes hiperpar치metros:\n",
        "    - `learning_rate` buscando valores flotantes en el rango (0.001, 0.1)\n",
        "    - `n_estimators` buscando valores enteros en el rango (50, 1000)\n",
        "    - `max_depth` buscando valores enteros en el rango (3, 10)\n",
        "    - `max_leaves` buscando valores enteros en el rango (0, 100)\n",
        "    - `min_child_weight` buscando valores enteros en el rango (1, 5)\n",
        "    - `reg_alpha` buscando valores flotantes en el rango (0, 1)\n",
        "    - `reg_lambda` buscando valores flotantes en el rango (0, 1)\n",
        "- De `OneHotEncoder`, optimice el hiperpar치metro `min_frequency` buscando el mejor valor flotante en el rango (0.0, 1.0)\n",
        "\n",
        "Para ello se pide los siguientes pasos:\n",
        "1. Implemente una funci칩n `objective()` que permita minimizar el `MAE` en el conjunto de validaci칩n. Use el m칠todo `.set_user_attr()` para almacenar el mejor pipeline entrenado. [10 puntos]\n",
        "2. Fije el tiempo de entrenamiento a 5 minutos. [1 punto]\n",
        "3. Optimizar el modelo y reportar el n칰mero de *trials*, el `MAE` y los mejores hiperpar치metros encontrados. 쮺칩mo cambian sus resultados con respecto a la secci칩n anterior? 쮸 qu칠 se puede deber esto? [3 puntos]\n",
        "4. Explique cada hiperpar치metro y su rol en el modelo. 쮿acen sentido los rangos de optimizaci칩n indicados? [5 puntos]\n",
        "5. Guardar su modelo en un archivo .pkl [1 punto]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "cell_id": "de5914621cc64cb0b1bacb9ff565a97e",
        "deepnote_cell_type": "code",
        "id": "kMXXi1ckI5v_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "N칰mero de trials: 45\n",
            "Mejor MAE en validaci칩n: 2267.431577256508\n",
            "Mejores hiperpar치metros: {'learning_rate': 0.09999979510356036, 'n_estimators': 365, 'max_depth': 6, 'max_leaves': 88, 'min_child_weight': 5, 'reg_alpha': 0.5062686131567655, 'reg_lambda': 0.24164993251711653, 'min_frequency': 0.05360688892585248}\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "# Inserte su c칩digo ac치\n",
        "\n",
        "# 1.\n",
        "def objective(trial):\n",
        "    # Inserte su c칩digo ac치\n",
        "\n",
        "    # Hiperpar치metros a optimizar\n",
        "    learning_rate = trial.suggest_float('learning_rate', 0.001, 0.1)\n",
        "    n_estimators = trial.suggest_int('n_estimators', 50, 1000)\n",
        "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
        "    max_leaves = trial.suggest_int('max_leaves', 0, 100)\n",
        "    min_child_weight = trial.suggest_int('min_child_weight', 1, 5)\n",
        "    reg_alpha = trial.suggest_float('reg_alpha', 0, 1)\n",
        "    reg_lambda = trial.suggest_float('reg_lambda', 0, 1)\n",
        "    min_frequency = trial.suggest_float('min_frequency', 0.0, 1.0)\n",
        "\n",
        "    numeric_transformer = StandardScaler()\n",
        "    categorical_transformer = OneHotEncoder(handle_unknown='ignore', min_frequency=min_frequency, sparse_output=False)\n",
        "\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numeric_transformer, numeric_cols),\n",
        "            ('cat', categorical_transformer, categorical_cols)\n",
        "        ]\n",
        "    )\n",
        "    preprocessor.set_output(transform='pandas')\n",
        "\n",
        "    preprocessor.fit(X_train)\n",
        "    # Obtener nombres de caracter칤sticas procesadas\n",
        "    feature_names = preprocessor.get_feature_names_out()\n",
        "    \n",
        "    # Restringir la monoton칤a en 'price'\n",
        "    monotonic_constraints = [0] * len(feature_names)\n",
        "    if 'num__price' in feature_names:\n",
        "        monotonic_constraints[feature_names.tolist().index('num__price')] = -1\n",
        "\n",
        "    monotonic_constraints_str = '(' + ','.join(map(str, monotonic_constraints)) + ')'\n",
        "\n",
        "    # Definir el pipeline\n",
        "    pipeline3 = Pipeline(steps=[\n",
        "        ('date_extractor', date_transformer),\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('regressor', XGBRegressor(\n",
        "            monotone_constraints=monotonic_constraints_str,\n",
        "            learning_rate=learning_rate,\n",
        "            n_estimators=n_estimators,\n",
        "            max_depth=max_depth,\n",
        "            max_leaves=max_leaves,\n",
        "            min_child_weight=min_child_weight,\n",
        "            reg_alpha=reg_alpha,\n",
        "            reg_lambda=reg_lambda,\n",
        "            random_state=seed\n",
        "        ))\n",
        "    ])\n",
        "\n",
        "    pipeline3.fit(X_train, y_train)\n",
        "    y_pred = pipeline3.predict(X_val)\n",
        "    mae = mean_absolute_error(y_val, y_pred)\n",
        "\n",
        "    trial.set_user_attr(\"best_pipeline\", pipeline3)\n",
        "\n",
        "    return mae\n",
        "\n",
        "# 2.\n",
        "study = optuna.create_study(direction='minimize', sampler=TPESampler(seed=seed))\n",
        "study.optimize(objective, timeout=300)  # Tiempo l칤mite de 5 minutos (300 segundos)\n",
        "\n",
        "# 3.\n",
        "# Obtener el mejor pipeline\n",
        "best_pipeline = study.best_trial.user_attrs[\"best_pipeline\"]\n",
        "\n",
        "# Reportar resultados\n",
        "print(f\"N칰mero de trials: {len(study.trials)}\")\n",
        "print(f\"Mejor MAE en validaci칩n: {study.best_value}\")\n",
        "print(f\"Mejores hiperpar치metros: {study.best_params}\")\n",
        "\n",
        "# 5. Guardar el mejor pipeline en un archivo .pkl\n",
        "with open('best_pipeline.pkl', 'wb') as f:\n",
        "    joblib.dump(best_pipeline, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. El MAE disminuyo de 2442 a 2267, lo que indica que la optimizaci칩n de hiperpar치metros con Optuna mejor칩 el rendimiento del modelo. Esto se debe a que el ajuste de par치metros permiti칩 un mejor equilibrio entre sobreajuste y subajuste, aumentando la precisi칩n en las predicciones.\n",
        "\n",
        "4. \n",
        "- learning_rate: Controla el tama침o de los pasos que da el modelo en cada iteraci칩n para minimizar la p칠rdida. Valores m치s peque침os hacen que el modelo aprenda m치s lento pero m치s preciso, por lo que hace sentido que el rango sea (0.001, 0.1).\n",
        "\n",
        "- n_estimators: Define cu치ntos 치rboles se entrenar치n. Un mayor n칰mero de 치rboles puede mejorar el ajuste, pero tambi칠n aumenta el riesgo de sobreajuste y el tiempo de entrenamiento. Por lo tanto, usar rango (50, 100) es razonable porque un n칰mero bajo de 치rboles (alrededor de 50) puede ser insuficiente para capturar patrones complejos, mientras que un n칰mero m치s alto (hasta 1000) puede aumentar la capacidad del modelo para aprender, aunque a costa de mayor tiempo de entrenamiento.\n",
        "\n",
        "- max_depth: Limita la profundidad de cada 치rbol, controlando cu치ntas decisiones puede tomar cada uno. Un valor m치s alto permite que el modelo capture m치s complejidad, pero puede sobreajustarse.  Un valor bajo (como 3) ayuda a prevenir el sobreajuste en problemas m치s sencillos, mientras que valores m치s altos (hasta 10) permiten al modelo captar relaciones m치s complejas en los datos. Por lo tanto, el rango indicado hace sentido.\n",
        "\n",
        "- max_leaves: Define el n칰mero m치ximo de hojas en cada 치rbol. Limitar las hojas ayuda a simplificar el modelo y a controlar la complejidad. En este caso un n칰mero bajo de hojas (cercano a 0) fuerza modelos m치s simples, mientras que un l칤mite de 100 hojas permite a los 치rboles tener m치s flexibilidad. Dejarlo en 0 puede permitir que el modelo encuentre autom치ticamente el mejor valor por lo que el rango indicado hace sentido.\n",
        "\n",
        "- min_child_weight: Establece el n칰mero m칤nimo de observaciones necesarias en un nodo hoja. Valores m치s altos reducen la posibilidad de que el modelo aprenda patrones espurios. El rango indicado est치 bien ajustado para evitar el sobreajuste. Valores m치s bajos (como 1) permiten nodos m치s peque침os y detallados, mientras que valores m치s altos (hasta 5) limitan las divisiones en los 치rboles, lo que ayuda a evitar que el modelo aprenda patrones irrelevantes.\n",
        "\n",
        "- reg_alpha y reg_lambda: Son los par치metros de regularizaci칩n L1 (reg_alpha) y L2 (reg_lambda). Ayudan a prevenir el sobreajuste penalizando los coeficientes excesivamente grandes. El rango indicado hace sentido, ya que, es adecuado para buscar el balance entre evitar el sobreajuste (con valores cercanos a 1) y no regularizar demasiado (cercano a 0).\n",
        "\n",
        "- min_frequency (en OneHotEncoder): Define el umbral m칤nimo para incluir una categor칤a en el codificador. Esto reduce el impacto de categor칤as raras, eliminando posibles fuentes de ruido. Al elegir un valor entre 0.0 y 1.0, se puede controlar la cantidad de categor칤as que se consideran, buscando un balance entre mantener la riqueza de los datos y reducir el ruido que podr칤an generar categor칤as muy poco frecuentes, por lo que el rango indicado hace sentido."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "5195ccfc37e044ad9453f6eb2754f631",
        "deepnote_cell_type": "markdown",
        "id": "ZglyD_QWI5wA"
      },
      "source": [
        "## 4. Optimizaci칩n de Hiperpar치metros con Optuna y Prunners (17 puntos)\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://i.pinimg.com/originals/90/16/f9/9016f919c2259f3d0e8fe465049638a7.gif\">\n",
        "</p>\n",
        "\n",
        "Despu칠s de optimizar el rendimiento de su modelo varias veces, Fiu le pregunta si no es posible optimizar el entrenamiento del modelo en s칤 mismo. Despu칠s de leer un par de post de personas de dudosa reputaci칩n en la *deepweb*, usted llega a la conclusi칩n que puede cumplir este objetivo mediante la implementaci칩n de **Prunning**.\n",
        "\n",
        "Vuelva a optimizar los mismos hiperpar치metros que la secci칩n pasada, pero esta vez utilizando **Prunning** en la optimizaci칩n. En particular, usted debe:\n",
        "\n",
        "- Responder: 쯈u칠 es prunning? 쮻e qu칠 forma deber칤a impactar en el entrenamiento? [2 puntos]\n",
        "- Redefinir la funci칩n `objective()` utilizando `optuna.integration.XGBoostPruningCallback` como m칠todo de **Prunning** [10 puntos]\n",
        "- Fijar nuevamente el tiempo de entrenamiento a 5 minutos [1 punto]\n",
        "- Reportar el n칰mero de *trials*, el `MAE` y los mejores hiperpar치metros encontrados. 쮺칩mo cambian sus resultados con respecto a la secci칩n anterior? 쮸 qu칠 se puede deber esto? [3 puntos]\n",
        "- Guardar su modelo en un archivo .pkl [1 punto]\n",
        "\n",
        "Nota: Si quieren silenciar los prints obtenidos en el prunning, pueden hacerlo mediante el siguiente comando:\n",
        "\n",
        "```\n",
        "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "```\n",
        "\n",
        "De implementar la opci칩n anterior, pueden especificar `show_progress_bar = True` en el m칠todo `optimize` para *m치s sabor*.\n",
        "\n",
        "Hint: Si quieren especificar par치metros del m칠todo .fit() del modelo a trav칠s del pipeline, pueden hacerlo por medio de la siguiente sintaxis: `pipeline.fit(stepmodelo__parametro = valor)`\n",
        "\n",
        "Hint2: Este <a href = https://stackoverflow.com/questions/40329576/sklearn-pass-fit-parameters-to-xgboost-in-pipeline>enlace</a> les puede ser de ayuda en su implementaci칩n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install optuna-integration[xgboost]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "eeaa967cd8f6426d8c54f276c17dce79",
        "deepnote_cell_type": "code",
        "id": "sST6Wtj5I5wA"
      },
      "outputs": [],
      "source": [
        "# Inserte su c칩digo ac치"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "8a081778cc704fc6bed05393a5419327",
        "deepnote_cell_type": "markdown",
        "id": "ZMiiVaCUI5wA"
      },
      "source": [
        "## 5. Visualizaciones (5 puntos)\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media.tenor.com/F-LgB1xTebEAAAAd/look-at-this-graph-nickelback.gif\">\n",
        "</p>\n",
        "\n",
        "\n",
        "Satisfecho con su trabajo, Fiu le pregunta si es posible generar visualizaciones que permitan entender el entrenamiento de su modelo.\n",
        "\n",
        "A partir del siguiente <a href = https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/005_visualization.html#visualization>enlace</a>, genere las siguientes visualizaciones:\n",
        "\n",
        "1. Gr치fico de historial de optimizaci칩n [1 punto]\n",
        "2. Gr치fico de coordenadas paralelas [1 punto]\n",
        "3. Gr치fico de importancia de hiperpar치metros [1 punto]\n",
        "\n",
        "Comente sus resultados:\n",
        "\n",
        "4. 쮻esde qu칠 *trial* se empiezan a observar mejoras notables en sus resultados? [0.5 puntos]\n",
        "5. 쯈u칠 tendencias puede observar a partir del gr치fico de coordenadas paralelas? [1 punto]\n",
        "6. 쮺u치les son los hiperpar치metros con mayor importancia para la optimizaci칩n de su modelo? [0.5 puntos]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "0e706dc9a8d946eda7a9eb1f0463c6d7",
        "deepnote_cell_type": "code",
        "id": "xjxAEENAI5wA"
      },
      "outputs": [],
      "source": [
        "# Inserte su c칩digo ac치"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "ac8a20f445d045a3becf1a518d410a7d",
        "deepnote_cell_type": "markdown",
        "id": "EoW32TA9I5wA"
      },
      "source": [
        "## 6. S칤ntesis de resultados (3 puntos)\n",
        "\n",
        "Finalmente:\n",
        "\n",
        "1. Genere una tabla resumen del MAE en el conjunto de validaci칩n obtenido en los 5 modelos entrenados desde Baseline hasta XGBoost con Constraints, Optuna y Prunning. [1 punto]\n",
        "2. Compare los resultados de la tabla y responda, 쯤u칠 modelo obtiene el mejor rendimiento? [0.5 puntos]\n",
        "3. Cargue el mejor modelo, prediga sobre el conjunto de **test** y reporte su MAE. [0.5 puntos]\n",
        "4. 쮼xisten diferencias con respecto a las m칠tricas obtenidas en el conjunto de validaci칩n? 쯇orqu칠 puede ocurrir esto? [1 punto]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jq5C6cDnJg9h"
      },
      "outputs": [],
      "source": [
        "# Inserte su c칩digo ac치"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "5c4654d12037494fbd385b4dc6bd1059",
        "deepnote_cell_type": "markdown",
        "id": "E_19tgBEI5wA"
      },
      "source": [
        "# Conclusi칩n\n",
        "Eso ha sido todo para el lab de hoy, recuerden que el laboratorio tiene un plazo de entrega de una semana. Cualquier duda del laboratorio, no duden en contactarnos por mail o U-cursos.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media.tenor.com/8CT1AXElF_cAAAAC/gojo-satoru.gif\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown",
        "id": "rAp9UxwiI5wA"
      },
      "source": [
        "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=87110296-876e-426f-b91d-aaf681223468' target=\"_blank\">\n",
        "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
        "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "deepnote": {},
    "deepnote_execution_queue": [],
    "deepnote_notebook_id": "f63d38450a6b464c9bb6385cf11db4d9",
    "deepnote_persisted_session": {
      "createdAt": "2023-11-09T16:18:30.203Z"
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
